{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "product_data = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\Admin\\\\Desktop\\\\DA books\\\\DA lesson\\\\Python\\\\product.csv\"\n",
    ")\n",
    "transactions_data = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\Admin\\\\Desktop\\\\DA books\\\\DA lesson\\\\Python\\\\transactions.csv\"\n",
    ")\n",
    "payment_data = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\Admin\\\\Desktop\\\\DA books\\\\DA lesson\\\\Python\\\\payment_report.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 492 entries, 0 to 491\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   product_id  492 non-null    int64 \n",
      " 1   category    492 non-null    object\n",
      " 2   team_own    492 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 11.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Check product data\n",
    "\n",
    "print(product_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 919 entries, 0 to 918\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   report_month   919 non-null    object\n",
      " 1   payment_group  919 non-null    object\n",
      " 2   product_id     919 non-null    int64 \n",
      " 3   source_id      919 non-null    int64 \n",
      " 4   volume         919 non-null    int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check payment_report data\n",
    "print(payment_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324002 entries, 0 to 1324001\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   transaction_id  1324002 non-null  int64  \n",
      " 1   merchant_id     1324002 non-null  int64  \n",
      " 2   volume          1324002 non-null  int64  \n",
      " 3   transType       1324002 non-null  int64  \n",
      " 4   transStatus     1324002 non-null  int64  \n",
      " 5   sender_id       1274943 non-null  float64\n",
      " 6   receiver_id     1159207 non-null  float64\n",
      " 7   extra_info      6095 non-null     object \n",
      " 8   timeStamp       1324002 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 90.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check transactions data\n",
    "print(transactions_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join product.csv and payment_report.csv, explore data  \n",
    "payment_enriched = pd.merge(payment_data, product_data, on = \"product_id\")\n",
    "payment_enriched[\"report_month\"] = pd.to_datetime(\n",
    "    payment_enriched[\"report_month\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 897 entries, 0 to 896\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   report_month   897 non-null    datetime64[ns]\n",
      " 1   payment_group  897 non-null    object        \n",
      " 2   product_id     897 non-null    int64         \n",
      " 3   source_id      897 non-null    int64         \n",
      " 4   volume         897 non-null    int64         \n",
      " 5   category       897 non-null    object        \n",
      " 6   team_own       897 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(3)\n",
      "memory usage: 49.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Payment enriched data\n",
    "#check missing values, datatype\n",
    "print(payment_enriched.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     report_month    product_id  source_id        volume\n",
      "count                         897    897.000000      897.0  8.970000e+02\n",
      "mean   2023-02-19 07:45:33.110368   1139.573021       45.0  1.338153e+08\n",
      "min           2023-01-01 00:00:00     12.000000       45.0  1.000000e+04\n",
      "25%           2023-02-01 00:00:00    634.000000       45.0  1.258000e+06\n",
      "50%           2023-03-01 00:00:00   1023.000000       45.0  7.469786e+06\n",
      "75%           2023-04-01 00:00:00   1578.000000       45.0  4.770741e+07\n",
      "max           2023-04-01 00:00:00  15067.000000       45.0  4.926051e+09\n",
      "std                           NaN   1161.547355        0.0  4.614672e+08\n"
     ]
    }
   ],
   "source": [
    "#check incorrect values\n",
    "print(payment_enriched.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change data type\n",
    "payment_enriched[\"payment_group\"] = payment_enriched[\"payment_group\"].astype('string')\n",
    "payment_enriched[\"category\"] = payment_enriched[\"category\"].astype('string')\n",
    "payment_enriched[\"team_own\"] = payment_enriched[\"team_own\"].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate data is: 0\n",
      "Null data in:\n",
      "report_month     0\n",
      "payment_group    0\n",
      "product_id       0\n",
      "source_id        0\n",
      "volume           0\n",
      "category         0\n",
      "team_own         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Recheck duplicate\n",
    "print(\"Duplicate data is: \" + str(payment_enriched.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recheck missing values\n",
    "print(\"Null data in:\")\n",
    "print(payment_enriched.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 897 entries, 0 to 896\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   report_month   897 non-null    datetime64[ns]\n",
      " 1   payment_group  897 non-null    string        \n",
      " 2   product_id     897 non-null    int64         \n",
      " 3   source_id      897 non-null    int64         \n",
      " 4   volume         897 non-null    int64         \n",
      " 5   category       897 non-null    string        \n",
      " 6   team_own       897 non-null    string        \n",
      "dtypes: datetime64[ns](1), int64(3), string(3)\n",
      "memory usage: 49.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Recheck datatype\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(payment_enriched.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     report_month    product_id  source_id        volume\n",
      "count                         897    897.000000      897.0  8.970000e+02\n",
      "mean   2023-02-19 07:45:33.110368   1139.573021       45.0  1.338153e+08\n",
      "min           2023-01-01 00:00:00     12.000000       45.0  1.000000e+04\n",
      "25%           2023-02-01 00:00:00    634.000000       45.0  1.258000e+06\n",
      "50%           2023-03-01 00:00:00   1023.000000       45.0  7.469786e+06\n",
      "75%           2023-04-01 00:00:00   1578.000000       45.0  4.770741e+07\n",
      "max           2023-04-01 00:00:00  15067.000000       45.0  4.926051e+09\n",
      "std                           NaN   1161.547355        0.0  4.614672e+08\n"
     ]
    }
   ],
   "source": [
    "#Recheck incorrect values\n",
    "print(payment_enriched.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Comment for payment_enriched data -->\n",
    "Regarding to payment_enriched data (Joining 2 table):\n",
    "Missing values : 0 values   => No action\n",
    "Duplicates : 0 values => No action\n",
    "Incorect data types : 0 values=> No action\n",
    "Incorrect Values : 0 values => No action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324002 entries, 0 to 1324001\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   transaction_id  1324002 non-null  int64  \n",
      " 1   merchant_id     1324002 non-null  int64  \n",
      " 2   volume          1324002 non-null  int64  \n",
      " 3   transType       1324002 non-null  int64  \n",
      " 4   transStatus     1324002 non-null  int64  \n",
      " 5   sender_id       1274943 non-null  float64\n",
      " 6   receiver_id     1159207 non-null  float64\n",
      " 7   extra_info      6095 non-null     object \n",
      " 8   timeStamp       1324002 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 90.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Transactions data\n",
    "#check missing values, datatype\n",
    "print(transactions_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       transaction_id   merchant_id        volume     transType   transStatus     sender_id   receiver_id     timeStamp\n",
      "count    1.324002e+06  1.324002e+06  1.324002e+06  1.324002e+06  1.324002e+06  1.274943e+06  1.159207e+06  1.324002e+06\n",
      "mean     3.002233e+09  2.460318e+03  2.388059e+05  6.979222e+00 -1.204625e+01  1.033938e+08  2.084884e+08  1.683130e+12\n",
      "std      1.042606e+07  3.304277e+03  9.681009e+05  7.459714e+00  5.577823e+01  6.234305e+08  9.287794e+08  1.707815e+08\n",
      "min      3.000000e+09  5.000000e+00  1.000000e+00  2.000000e+00 -1.333000e+03  1.000001e+07 -6.300000e+01  1.682874e+12\n",
      "25%      3.001121e+09  3.050000e+02  1.000000e+04  2.000000e+00  1.000000e+00  1.005657e+07  1.526700e+05  1.682994e+12\n",
      "50%      3.002200e+09  2.250000e+03  3.000000e+04  2.000000e+00  1.000000e+00  1.094193e+07  7.025130e+06  1.683097e+12\n",
      "75%      3.003255e+09  2.270000e+03  1.000000e+05  8.000000e+00  1.000000e+00  2.101266e+07  3.151238e+07  1.683269e+12\n",
      "max      6.000066e+09  1.625250e+05  7.869148e+07  3.000000e+01  1.000000e+00  6.993439e+09  2.100000e+10  1.683479e+12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Check incorrect values, \n",
    "print(transactions_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_id          0\n",
      "merchant_id             0\n",
      "volume                  0\n",
      "transType               0\n",
      "transStatus             0\n",
      "sender_id           49059\n",
      "receiver_id        164795\n",
      "extra_info        1317907\n",
      "timeStamp               0\n",
      "dtype: int64\n",
      "Num of Duplicated data is: 28\n"
     ]
    }
   ],
   "source": [
    "#find duplicates data\n",
    "print(transactions_data.isna().sum())\n",
    "\n",
    "print(\"Num of Duplicated data is: \" + str(transactions_data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change data type, fill null, convert incorrect values(negative to positive)\n",
    "transactions_data[\"receiver_id\"] = transactions_data[\"receiver_id\"].abs()\n",
    "transactions_data[\"transStatus\"] = transactions_data[\"transStatus\"].abs()\n",
    "transactions_data[\"sender_id\"] = transactions_data[\"sender_id\"].fillna(0).astype(int)\n",
    "transactions_data[\"receiver_id\"] = transactions_data[\"receiver_id\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove dup\n",
    "transaction_remove_dup = transactions_data.drop_duplicates(subset= \"transaction_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Removed duplicated data is :0\n"
     ]
    }
   ],
   "source": [
    "#Recheck duplicates\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Num of Removed duplicated data is :\" + str(transaction_remove_dup.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null data in:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1323974 entries, 0 to 1324001\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   transaction_id  1323974 non-null  int64 \n",
      " 1   merchant_id     1323974 non-null  int64 \n",
      " 2   volume          1323974 non-null  int64 \n",
      " 3   transType       1323974 non-null  int64 \n",
      " 4   transStatus     1323974 non-null  int64 \n",
      " 5   sender_id       1323974 non-null  int64 \n",
      " 6   receiver_id     1323974 non-null  int64 \n",
      " 7   extra_info      6095 non-null     object\n",
      " 8   timeStamp       1323974 non-null  int64 \n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 101.0+ MB\n",
      "None\n",
      "transaction_id          0\n",
      "merchant_id             0\n",
      "volume                  0\n",
      "transType               0\n",
      "transStatus             0\n",
      "sender_id               0\n",
      "receiver_id             0\n",
      "extra_info        1317879\n",
      "timeStamp               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Recheck missing values , datatype\n",
    "print(\"Null data in:\")\n",
    "print(transaction_remove_dup.info())\n",
    "\n",
    "print(transaction_remove_dup.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       transaction_id   merchant_id        volume     transType   transStatus     sender_id   receiver_id     timeStamp\n",
      "count    1.323974e+06  1.323974e+06  1.323974e+06  1.323974e+06  1.323974e+06  1.323974e+06  1.323974e+06  1.323974e+06\n",
      "mean     3.002234e+09  2.460332e+03  2.388093e+05  6.979182e+00  1.393273e+01  9.956116e+07  1.825382e+08  1.683130e+12\n",
      "std      1.042617e+07  3.304293e+03  9.681107e+05  7.459665e+00  5.533747e+01  6.120781e+08  8.717817e+08  1.707816e+08\n",
      "min      3.000000e+09  5.000000e+00  1.000000e+00  2.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  1.682874e+12\n",
      "25%      3.001121e+09  3.050000e+02  1.000000e+04  2.000000e+00  1.000000e+00  1.004014e+07  4.059475e+04  1.682994e+12\n",
      "50%      3.002200e+09  2.250000e+03  3.000000e+04  2.000000e+00  1.000000e+00  1.057187e+07  3.529736e+06  1.683097e+12\n",
      "75%      3.003255e+09  2.270000e+03  1.000000e+05  8.000000e+00  1.000000e+00  2.100163e+07  2.451345e+07  1.683269e+12\n",
      "max      6.000066e+09  1.625250e+05  7.869148e+07  3.000000e+01  1.333000e+03  6.993439e+09  2.100000e+10  1.683479e+12\n"
     ]
    }
   ],
   "source": [
    "#Recheck incorrect values\n",
    "print(transaction_remove_dup.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Comment for transactions_data -->\n",
    "Regarding to transacion_data :\n",
    "Missing data : sender_id (49059). receiver_id (164795), extra_info (1317907)  => fill null sender_id, receiver_id\n",
    "Duplicates : 28 values => Remove duplicates\n",
    "Incorect data types : sender_id. receiver_id (Float) => Convert to (Int) data type\n",
    "Incorrect Values : receiver_id, transStatus gets negative values  => Convert to suitable values (positive values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 volume\n",
      "product_id             \n",
      "1976        61797583647\n",
      "429         14667676567\n",
      "372         13713658515\n"
     ]
    }
   ],
   "source": [
    "#sum volume and get top 3 products\n",
    "total_volume = pd.DataFrame(payment_data.groupby(\"product_id\")[\"volume\"].sum())\n",
    "top_3_productids = total_volume.sort_values(\"volume\", ascending= False).head(3)\n",
    "\n",
    "print(top_3_productids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  team_own\n",
      "0            12         1\n",
      "1            15         1\n",
      "2            17         1\n",
      "3            18         1\n",
      "4            19         1\n",
      "..          ...       ...\n",
      "303        2408         1\n",
      "304        2419         1\n",
      "305        2587         1\n",
      "306       10039         1\n",
      "307       15067         1\n",
      "\n",
      "[308 rows x 2 columns]\n",
      "     product_id  team_own\n",
      "0            12         1\n",
      "1            15         1\n",
      "2            17         1\n",
      "3            18         1\n",
      "4            19         1\n",
      "..          ...       ...\n",
      "303        2408         1\n",
      "304        2419         1\n",
      "305        2587         1\n",
      "306       10039         1\n",
      "307       15067         1\n",
      "\n",
      "[308 rows x 2 columns]\n",
      "Empty DataFrame\n",
      "Columns: [product_id, team_own]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#total unique data, product owned by 1 team\n",
    "total_unique = payment_enriched.groupby(\n",
    "    \"product_id\", as_index = False)[\"team_own\"].nunique()\n",
    "team_normal = total_unique[total_unique[\"team_own\"] == 1]\n",
    "team_abnormal = total_unique[total_unique[\"team_own\"] != 1]\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(total_unique)\n",
    "print(team_normal)\n",
    "print(team_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            volume  rank\n",
      "team_own                \n",
      "APS       51141753   1.0\n"
     ]
    }
   ],
   "source": [
    "#total volume by team since 2023-04\n",
    "total = pd.DataFrame(\n",
    "    payment_enriched[payment_enriched[\"report_month\"].dt.quarter >= 2]\n",
    "    .groupby(\"team_own\")[\"volume\"]\n",
    "    .sum()\n",
    ")\n",
    "total[\"rank\"] = total.sort_values(\"volume\").rank()\n",
    "print(total[total[\"rank\"]== 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            volume  rank1\n",
      "category                 \n",
      "PXXXXXE   25232438    1.0\n"
     ]
    }
   ],
   "source": [
    "#find category have lowest contribution to that team (APS)\n",
    "total1 = pd.DataFrame(\n",
    "    payment_enriched[\n",
    "        (payment_enriched[\"report_month\"].dt.quarter >= 2) \n",
    "        & (payment_enriched[\"team_own\"] == \"APS\")\n",
    "    ]\n",
    "    .groupby(\"category\")[\"volume\"]\n",
    "    .sum()\n",
    ")\n",
    "total1[\"rank1\"] = total1.sort_values(\"volume\").rank()\n",
    "print(total1[total1[\"rank1\"]== 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                volume  rank_cont\n",
      "source_id                        \n",
      "38         36527454759        1.0\n"
     ]
    }
   ],
   "source": [
    "contribution = pd.DataFrame(\n",
    "    payment_data[payment_data[\"payment_group\"] == \"refund\"]\n",
    "    .groupby(\"source_id\")[\"volume\"]\n",
    "    .sum()\n",
    ")\n",
    "contribution[\"rank_cont\"] = contribution.sort_values(\"volume\", ascending = False).rank(ascending= False)\n",
    "print(contribution[contribution[\"rank_cont\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         transaction_id  merchant_id   volume  transType  transStatus  sender_id  receiver_id extra_info      timeStamp            transaction_type\n",
      "0            3002692434            5   100000         24            1   10199794       199794        NaN  1682932054455        Invalid Transactions\n",
      "1            3002692437          305    20000          2            1   14022211     14022211        NaN  1682932054912         Payment Transaction\n",
      "2            3001960110         7255    48605         22            1          0     10530940        NaN  1682932055000        Invalid Transactions\n",
      "3            3002680710         2270  1500000          2            1   10059206        59206        NaN  1682932055622    Top Up Money Transaction\n",
      "4            3002680713         2275    90000          2            1   10004711         4711        NaN  1682932056197         Payment Transaction\n",
      "...                 ...          ...      ...        ...          ...        ...          ...        ...            ...                         ...\n",
      "1323997      3003723030          305    20000          2            1   24524311            0        NaN  1683035672634         Payment Transaction\n",
      "1323998      3003723033         2270   100000          2            1   10277242       277242        NaN  1683035672876    Top Up Money Transaction\n",
      "1323999      3003723036         2270   100000          2            1   10144599       144599        NaN  1683035672892    Top Up Money Transaction\n",
      "1324000      3003723039            5      400         22            1   10028007     21013762        NaN  1683035672896        Invalid Transactions\n",
      "1324001      3003602967         2250        1          8            1   38559843     24501638        NaN  1683035673053  Transfer Money Transaction\n",
      "\n",
      "[1323974 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9120\\2163614259.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_remove_dup[\"transaction_type\"]= np.select(\n"
     ]
    }
   ],
   "source": [
    "#list of categories\n",
    "transactions_data[\"sender_id\"] = transactions_data[\"sender_id\"].fillna(0).astype(int)\n",
    "transactions_data[\"receiver_id\"] = transactions_data[\"receiver_id\"].fillna(0).astype(int)\n",
    "transaction_remove_dup = transactions_data.drop_duplicates(subset= \"transaction_id\")\n",
    "transaction_categories = [\n",
    "    \"Bank Transfer Transaction\", \n",
    "    \"Withdraw Money Transaction\", \n",
    "    \"Top Up Money Transaction\",\n",
    "    \"Payment Transaction\",\n",
    "    \"Transfer Money Transaction\", \n",
    "    \"Split Bill Transaction\"\n",
    "]\n",
    "#list of conditions, through by each position in list\n",
    "conditions = [\n",
    "    (transaction_remove_dup[\"transType\"] == 2) \n",
    "    & (transaction_remove_dup[\"merchant_id\"] == 1205),\n",
    "    (transaction_remove_dup[\"transType\"] == 2) \n",
    "    & (transaction_remove_dup[\"merchant_id\"] == 2260),\n",
    "    (transaction_remove_dup[\"transType\"] == 2) \n",
    "    & (transaction_remove_dup[\"merchant_id\"] == 2270),\n",
    "    (transaction_remove_dup[\"transType\"] == 2) \n",
    "    & (~transaction_remove_dup[\"merchant_id\"].isin([1205, 2260, 2270])),\n",
    "    (transaction_remove_dup[\"transType\"] == 8) \n",
    "    & (transaction_remove_dup[\"merchant_id\"] == 2250),\n",
    "    (transaction_remove_dup[\"transType\"] == 8) \n",
    "    & (~transaction_remove_dup[\"merchant_id\"].isin([2250]))]\n",
    "transaction_remove_dup[\"transaction_type\"]= np.select(\n",
    "    conditions, transaction_categories, default = \"Invalid Transactions\"\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(transaction_remove_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            num_transactions  total_volume  num_senders  num_receivers\n",
      "transaction_type                                                                      \n",
      "Bank Transfer Transaction              37879   50605806190        23156           9272\n",
      "Payment Transaction                   398665   71850608441       139583         113297\n",
      "Split Bill Transaction                  1376       4901464         1323            572\n",
      "Top Up Money Transaction              290498  108605618829       110409         110409\n",
      "Transfer Money Transaction            341173   37032880492        39021          34585\n",
      "Withdraw Money Transaction             33725   23418181420        24814          24814\n"
     ]
    }
   ],
   "source": [
    "#num of transactions, volume, senders, receivers unique.\n",
    "summarize_transaction = (\n",
    "    transaction_remove_dup[\n",
    "        transaction_remove_dup[\"transaction_type\"] != \"Invalid Transactions\"\n",
    "    ]\n",
    "    .groupby(\"transaction_type\")\n",
    "    .agg(\n",
    "        num_transactions = (\"transaction_id\", \"nunique\"),\n",
    "        total_volume = (\"volume\", \"sum\"),\n",
    "        num_senders = (\"sender_id\", \"nunique\"),\n",
    "        num_receivers = (\"receiver_id\", \"nunique\")\n",
    "    )\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(summarize_transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "# EDA Results\n",
    "# - Regarding to payment_enriched data (Joining 2 payment_report.csv and product.csv file), it can be seen that no missing values. Moreover, there were no duplicates, inccorect data type as well as incorrect values in these dataset, so no actions needed for these exploratory.\n",
    "# - According to transacion_data : missing data is identified in sender_id (49059). receiver_id (164795), extra_info (1317907) columns, however just sender_id and receiver_id are needed for filling null values action. Besides, the dataset contained 28 duplicates rows, so that is required to be removed for enhacing data accuracy. Furthermore, sender_id and receiver_id need to convert from float to Integer data type for clear meaning. Especially, negative values are found in receiver_id, transStatus , these are inccorected values that need to be converted to positive values.\n",
    "# #Key Finding\n",
    "#  - Top three products ID: with the highest transaction volume are 1976, 429 and 372 orderly. From these consequence , Company can prioritize product marketing, marketing campaigns for next seasons as well as resource allocation.\n",
    "#  - Performance: since Q2 2023,  APS team can be seen as the worst performance with the lowest volume, the least productive category is PXXXXXE. This team should attention on the next strategies to have a better improvement, reach target to enhance team performance\n",
    "#  - Refund Transactions analysis: Moreover , The analysis of refund transactions indicated that the source ID contributing the most was 38, with the volume of 36,527,454,759. Understanding the sources and reasons behind these transactions can inform strategies to minimize future occurrences, reduce operational costs, and enhance customer satisfaction.\n",
    "#  - Payment , Top up Money and Transfer Money are the three main reasons customers use e-wallet, within Payment have the highest number of transactions, while most people Top Up Money the the greatest amount of money to e-wallet for various daily expense.\n",
    "#  - Overall, These findings emphasize key factors relating to product performance, team performance, contribution and transactions dynamic within e-wallet service. By seeking for, analysing and addressing many identified issues and difficult challenges as well as utilizing the insights gained, the company can improve efficiency, team performance in order to devote overall financial performance as well as company development.\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
